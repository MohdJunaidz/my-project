{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM2j2BFBWzQaVh4asfIIrlp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohdJunaidz/my-project/blob/main/Junaid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6Ady9vnrEA5",
        "outputId": "bd4e3505-2dec-4ee2-87fa-f97f7e9b7a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())  # Should print True if GPU is detected\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj6l0VXnsuyd",
        "outputId": "f0794727-8b85-47df-ea75-5cbaaeb1a2cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Feb 19 10:13:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             11W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rafiep/CTran.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLyfWpQptogk",
        "outputId": "7f848019-9aaa-4565-8496-ce9ef5ee412d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CTran'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 44 (delta 13), reused 26 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (44/44), 918.54 KiB | 15.57 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Downloading bert-base-uncased/pytorch_model.bin (440 MB)\n",
            "Error downloading object: bert-base-uncased/pytorch_model.bin (0974173): Smudge error: Error downloading bert-base-uncased/pytorch_model.bin (097417381d6c7230bd9e3557456d726de6e83245ec8b24f529f60198a67b203a): batch response: This repository is over its data quota. Account responsible for LFS bandwidth should purchase more data packs to restore access.\n",
            "\n",
            "Errors logged to /content/CTran/.git/lfs/logs/20250219T113201.429742809.log\n",
            "Use `git lfs logs last` to view the log.\n",
            "error: external filter 'git-lfs filter-process' failed\n",
            "fatal: bert-base-uncased/pytorch_model.bin: smudge filter lfs failed\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O bert-large-uncased/pytorch_model.bin \"https://huggingface.co/bert-large-uncased/resolve/main/pytorch_model.bin\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WXaFTAzuTWT",
        "outputId": "add9135f-1535-4efc-e4d1-03dc60ead302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-large-uncased/pytorch_model.bin: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O bert-base-uncased/pytorch_model.bin \"https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S26yejaOugA2",
        "outputId": "e6e8b8ca-813d-42d0-945d-760d7c4fe2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-base-uncased/pytorch_model.bin: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p CTran/bert-base-uncased\n"
      ],
      "metadata": {
        "id": "KZ2k2VhRuwpK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipy3l0Dbu2X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O CTran/bert-base-uncased/pytorch_model.bin \"https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OQA62hUvQD4",
        "outputId": "047c7b58-b512-4ec1-d029-9c678585df81"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-19 11:33:20--  https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.202.40, 13.35.202.34, 13.35.202.97, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.202.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/bert-base-uncased/097417381d6c7230bd9e3557456d726de6e83245ec8b24f529f60198a67b203a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1739968400&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTk2ODQwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9iZXJ0LWJhc2UtdW5jYXNlZC8wOTc0MTczODFkNmM3MjMwYmQ5ZTM1NTc0NTZkNzI2ZGU2ZTgzMjQ1ZWM4YjI0ZjUyOWY2MDE5OGE2N2IyMDNhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=kQQYPFNlYQ2oIHQFZcRcfBSiT2hnyBgwZutm6mP9BeCBdfh32xMW9nKOazo64UVG2F-UoJfxZz%7EGB-Kvo2jCR2lBtUn4WWgyxFNWi5E2fcKuJp1OjIa%7EF-axL6ETqhLC72pY565Hf%7EhAFVG3oRuka%7EvWauExRR-dmjnXvmhntDooiM9SKd-2A%7E8Ab6zV-GzzQ82C6XyphjqCz7dN0gmecI2PKE1fmCwP0WZRRSKSino6AkpenecknlA4JW4B42Zh77wyw16ohmsY3ZtcvE3ZteNk%7E3XaHIDO86JX6zXqEbYHTinSYzyliIpdtLekiyCATyNGezxWsoGjTqO0cbb0uQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-02-19 11:33:20--  https://cdn-lfs.hf.co/bert-base-uncased/097417381d6c7230bd9e3557456d726de6e83245ec8b24f529f60198a67b203a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1739968400&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczOTk2ODQwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9iZXJ0LWJhc2UtdW5jYXNlZC8wOTc0MTczODFkNmM3MjMwYmQ5ZTM1NTc0NTZkNzI2ZGU2ZTgzMjQ1ZWM4YjI0ZjUyOWY2MDE5OGE2N2IyMDNhP3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiJ9XX0_&Signature=kQQYPFNlYQ2oIHQFZcRcfBSiT2hnyBgwZutm6mP9BeCBdfh32xMW9nKOazo64UVG2F-UoJfxZz%7EGB-Kvo2jCR2lBtUn4WWgyxFNWi5E2fcKuJp1OjIa%7EF-axL6ETqhLC72pY565Hf%7EhAFVG3oRuka%7EvWauExRR-dmjnXvmhntDooiM9SKd-2A%7E8Ab6zV-GzzQ82C6XyphjqCz7dN0gmecI2PKE1fmCwP0WZRRSKSino6AkpenecknlA4JW4B42Zh77wyw16ohmsY3ZtcvE3ZteNk%7E3XaHIDO86JX6zXqEbYHTinSYzyliIpdtLekiyCATyNGezxWsoGjTqO0cbb0uQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.170.229.19, 3.170.229.125, 3.170.229.105, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.170.229.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 440473133 (420M) [application/octet-stream]\n",
            "Saving to: ‘CTran/bert-base-uncased/pytorch_model.bin’\n",
            "\n",
            "CTran/bert-base-unc 100%[===================>] 420.07M  38.1MB/s    in 5.9s    \n",
            "\n",
            "2025-02-19 11:33:27 (70.7 MB/s) - ‘CTran/bert-base-uncased/pytorch_model.bin’ saved [440473133/440473133]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CTran\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2StCtrNWwVY-",
        "outputId": "4b6eae2a-192b-4177-82b3-0dc216bfe24a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CTran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vgdGZdLlwcKF",
        "outputId": "70ec5481-190b-42f1-8dbc-1e7a576f7d66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting scikit_learn==1.2.2 (from -r requirements.txt (line 2))\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting torch==1.13.0 (from -r requirements.txt (line 3))\n",
            "  Downloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting tqdm==4.64.1 (from -r requirements.txt (line 4))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.25.1 (from -r requirements.txt (line 5))\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0->-r requirements.txt (line 3))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1->-r requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2024.12.14)\n",
            "Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, tqdm, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nvidia-cudnn-cu11, transformers, torch, scikit_learn\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: scikit_learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.33.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 scikit_learn-1.2.2 tokenizers-0.13.3 torch-1.13.0 tqdm-4.64.1 transformers-4.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "1fe06f9c82014d588be2717f2808817f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall numpy scikit-learn torch tqdm transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2J4eyW__yOMM",
        "outputId": "05c014e6-6af3-4fae-c0da-2b016d239bd9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.23.5\n",
            "Uninstalling numpy-1.23.5:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/f2py3\n",
            "    /usr/local/bin/f2py3.11\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-1.23.5.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.23.5\n",
            "Found existing installation: scikit-learn 1.2.2\n",
            "Uninstalling scikit-learn-1.2.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/scikit_learn-1.2.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/scikit_learn.libs/libgomp-a34b3233.so.1.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/sklearn/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled scikit-learn-1.2.2\n",
            "Found existing installation: torch 1.13.0\n",
            "Uninstalling torch-1.13.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.11/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch-1.13.0.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.11/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled torch-1.13.0\n",
            "Found existing installation: tqdm 4.64.1\n",
            "Uninstalling tqdm-4.64.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/tqdm\n",
            "    /usr/local/lib/python3.11/dist-packages/tqdm-4.64.1.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/tqdm/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tqdm-4.64.1\n",
            "Found existing installation: transformers 4.25.1\n",
            "Uninstalling transformers-4.25.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers-4.25.1.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/transformers/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF6XkftXyjPD",
        "outputId": "4900744d-c386-4e68-f83e-c266e959074f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQJQu5v60fWa",
        "outputId": "89c2f21b-5b73-4497-87a4-a77ee75af5ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K75GdDro0yf6",
        "outputId": "ddd46629-0b03-4f44-9a6a-fea14766b233"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd content/CTran\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNeI-ueE1a-Q",
        "outputId": "9ae254d5-5d75-449d-f234-0c3a75ca9b5e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CTran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DRxjy9xM1uZj",
        "outputId": "e907dd32-d564-4602-9ed1-c800ed0bd274"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5 (from -r requirements.txt (line 1))\n",
            "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting scikit_learn==1.2.2 (from -r requirements.txt (line 2))\n",
            "  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting torch==1.13.0 (from -r requirements.txt (line 3))\n",
            "  Using cached torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting tqdm==4.64.1 (from -r requirements.txt (line 4))\n",
            "  Using cached tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "Collecting transformers==4.25.1 (from -r requirements.txt (line 5))\n",
            "  Using cached transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.7.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (0.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2024.12.14)\n",
            "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "Using cached torch-1.13.0-cp311-cp311-manylinux1_x86_64.whl (890.2 MB)\n",
            "Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "Installing collected packages: tqdm, numpy, transformers, torch, scikit_learn\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "scikit-image 0.25.0 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "pymc 5.19.1 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "bigframes 1.33.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.1.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.13.0 which is incompatible.\n",
            "chex 0.1.88 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5 scikit_learn-1.2.2 torch-1.13.0 tqdm-4.64.1 transformers-4.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "88f6f7d84d0741efa553073aa536fdbc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat CTran/requirements.txt\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmIfCcK-2C3d",
        "outputId": "aafdfe20-0e1c-472f-ab15-c75c568dff1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy==1.23.5\n",
            "scikit_learn==1.2.2\n",
            "torch==1.13.0\n",
            "tqdm==4.64.1\n",
            "transformers==4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLXYd0Xa24lA",
        "outputId": "dbc92e1f-13df-4540-f1cc-4f1e36c0ea61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mCTran\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGY1ghEt3T6w",
        "outputId": "ec115f38-e04e-47cf-bb8d-4d6511ca4bb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CTran\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzpSpNzy3Y3N",
        "outputId": "334ec61f-18f8-4d47-f424-a43bb07bb960"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CTran\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4lbDa773gmT",
        "outputId": "5b4d410c-7718-4c1f-9944-66aa7c84390a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbert-base-uncased\u001b[0m/  CTran.ipynb  \u001b[01;34mdataset\u001b[0m/  LICENSE  README.md  requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ZKDHfAkA9gdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7892b60f-c820-4c47-fcc3-652c4b9d0ec7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn==1.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (1.13.0)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (4.64.1)\n",
            "Requirement already satisfied: transformers==4.25.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.25.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn==1.2.2->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (4.12.2)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==1.13.0->-r requirements.txt (line 3)) (11.7.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1->-r requirements.txt (line 5)) (0.13.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r requirements.txt (line 3)) (0.45.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1->-r requirements.txt (line 5)) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "cs4NtfssDXUe",
        "outputId": "945fc780-020b-4259-cfb8-13f569a14c66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d90391ac-da7d-45fb-97db-2fc704b1da8a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d90391ac-da7d-45fb-97db-2fc704b1da8a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8ZIAgUqLP0Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [code]\n",
        "# First step is to import the needed libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "import math\n",
        "import re\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# %% [code]\n",
        "# in this section we define static values and variables for ease of access and testing\n",
        "_fn=\"final\" # file unique id for saving and loading models\n",
        "bert_base='./bert-base-uncased/'\n",
        "bert_large='./bert-large-uncased/'\n",
        "\n",
        "snips_train=\"./dataset/snips_train.iob\"\n",
        "snips_test=\"./dataset/snips_test.iob\"\n",
        "atis_train=\"./dataset/atis.train.w-intent.iob\"\n",
        "atis_test=\"./dataset/atis.test.w-intent.iob\"\n",
        "#ENV variables directly affect the model's behaviour\n",
        "ENV_DATASET_TRAIN=atis_train\n",
        "ENV_DATASET_TEST=atis_test\n",
        "\n",
        "ENV_BERT_ID_CLS=False # use cls token for id classification\n",
        "ENV_EMBEDDING_SIZE=768# dimention of embbeding, bertbase=768,bertlarge&elmo=1024\n",
        "ENV_BERT_ADDR=bert_base\n",
        "ENV_SEED=1331\n",
        "ENV_CNN_FILTERS=128\n",
        "ENV_CNN_KERNELS=4\n",
        "ENV_HIDDEN_SIZE=ENV_CNN_FILTERS*ENV_CNN_KERNELS\n",
        "\n",
        "#these are related to training\n",
        "BATCH_SIZE=16\n",
        "LENGTH=60\n",
        "STEP_SIZE=50\n",
        "\n",
        "# you must use cuda to run this code. if this returns false, you can not proceed.\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "if USE_CUDA:\n",
        "    print(\"You are using cuda. Good!\")\n",
        "else:\n",
        "    print('You are NOT using cuda! Some problems may occur.')\n",
        "\n",
        "torch.manual_seed(ENV_SEED)\n",
        "random.seed(ENV_SEED)\n",
        "Execution output\n",
        "0KB\n",
        "\tStream\n",
        "\t\tYou are using cuda. Good!\n",
        "\n",
        "Text cell <undefined>\n",
        "# %% [markdown]\n",
        "implement dataloader\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "\n",
        "#this function converts tokens to ids and then to a tensor\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = list(map(lambda w: to_ix[w] if w in to_ix.keys() else to_ix[\"<UNK>\"], seq))\n",
        "    tensor = Variable(torch.LongTensor(idxs)).cuda() if USE_CUDA else Variable(torch.LongTensor(idxs))\n",
        "    return tensor\n",
        "# this function turns class text to id\n",
        "def prepare_intent(intent, to_ix):\n",
        "    idxs = to_ix[intent] if intent in to_ix.keys() else to_ix[\"UNKNOWN\"]\n",
        "    return idxs\n",
        "# converts numbers to <NUM> TAG\n",
        "def number_to_tag(txt):\n",
        "    return \"<NUM>\" if txt.isdecimal() else txt\n",
        "\n",
        "# Here we remove multiple spaces and punctuation which cause errors in tokenization for bert & elmo.\n",
        "def remove_punc(mlist):\n",
        "    mlist = [re.sub(\" +\",\" \",t.split(\"\\t\")[0][4:-4]) for t in mlist] # remove spaces down to 1\n",
        "    temp_train_tokens = []\n",
        "    # punct remove example:  play samuel-el jackson from 2009 - 2010 > play samuelel jackson from 2009 - 2010\n",
        "    for row in mlist:\n",
        "        tokens = row.split(\" \")\n",
        "        newtokens = []\n",
        "        for token in tokens:\n",
        "            newtoken = re.sub(r\"[.,'\\\"\\\\/\\-:&’—=–官方杂志¡…“”~%]\",r\"\",token) # remove punc\n",
        "            newtoken = re.sub(r\"[楽園追放�]\",r\"A\",newtoken)\n",
        "            newtokens.append(newtoken if len(token)>1 else token)\n",
        "        if newtokens[-1]==\"\":\n",
        "            newtokens.pop(-1)\n",
        "        if newtokens[0]==\"\":\n",
        "            newtokens.pop(0)\n",
        "        temp_train_tokens.append(\" \".join(newtokens))\n",
        "    return temp_train_tokens\n",
        "# this function returns the main tokens so that we can apply tagging on them. see original paper.\n",
        "def get_subtoken_mask(current_tokens,bert_tokenizer):\n",
        "    temp_mask = []\n",
        "    for i in current_tokens:\n",
        "        temp_row_mask = []\n",
        "        temp_row_mask.append(False) # for cls token\n",
        "        temp = bert_tokenizer.tokenize(i)\n",
        "        for j in temp:\n",
        "            temp_row_mask.append(j[:2]!=\"##\")\n",
        "        while len(temp_row_mask)<LENGTH:\n",
        "            temp_row_mask.append(False)\n",
        "        temp_mask.append(temp_row_mask)\n",
        "        if sum(temp_row_mask)!=len(i.split(\" \")):\n",
        "            print(f\"inconsistent:{temp}\")\n",
        "            print(i)\n",
        "            print(sum(temp_row_mask))\n",
        "            print(len(i.split(\" \")))\n",
        "    return torch.tensor(temp_mask).cuda()\n",
        "\n",
        "flatten = lambda l: [number_to_tag(item) for sublist in l for item in sublist]\n",
        "\n",
        "Text cell <undefined>\n",
        "# %% [markdown]\n",
        "# Data load and Preprocessing\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "def tokenize_dataset(dataset_address):\n",
        "    # added tokenizer and tokens for\n",
        "    bert_tokenizer = torch.hub.load(ENV_BERT_ADDR, 'tokenizer', ENV_BERT_ADDR,verbose=False,source=\"local\")#38toks snips,52Atis\n",
        "    ##open database and read line by line\n",
        "    dataset = open(dataset_address,\"r\").readlines()\n",
        "    print(\"example input:\"+dataset[0])\n",
        "    ##remove last character of lines -\\n- in train file\n",
        "    dataset = [t[:-1] for t in dataset]\n",
        "    #converts string to array of tokens + array of tags + target intent [array with x=3 and y dynamic]\n",
        "    dataset_tokens = remove_punc(dataset)\n",
        "    dataset_subtoken_mask = get_subtoken_mask(dataset_tokens,bert_tokenizer)\n",
        "    dataset_toks = bert_tokenizer.batch_encode_plus(dataset_tokens,max_length=LENGTH,add_special_tokens=True,return_tensors='pt'\n",
        "                                                  ,return_attention_mask=True , padding='max_length',truncation=True)\n",
        "    dataset = [[re.sub(\" +\",\" \",t.split(\"\\t\")[0]).split(\" \"),t.split(\"\\t\")[1].split(\" \")[:-1],t.split(\"\\t\")[1].split(\" \")[-1]] for t in dataset]\n",
        "    #removes BOS, EOS from array of tokens and tags\n",
        "    dataset = [[t[0][1:-1],t[1][1:],t[2]] for t in dataset]\n",
        "    return dataset, dataset_subtoken_mask,dataset_toks\n",
        "train,train_subtoken_mask,train_toks = tokenize_dataset(ENV_DATASET_TRAIN)\n",
        "test, test_subtoken_mask, test_toks = tokenize_dataset(ENV_DATASET_TEST)\n",
        "Execution output\n",
        "1KB\n",
        "\tStream\n",
        "\t\texample input:BOS i want to fly from boston at 838 am and arrive in denver at 1110 in the morning EOS\t O O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day atis_flight\n",
        "\n",
        "\t\texample input:BOS i would like to find a flight from charlotte to las vegas that makes a stop in st. louis EOS\tO O O O O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O O O O O B-stoploc.city_name I-stoploc.city_name atis_flight\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "#convert above array to separate lists\n",
        "seq_in,seq_out, intent = list(zip(*train))\n",
        "seq_in_test,seq_out_test, intent_test = list(zip(*test.copy()))\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "# Create Sets of unique tokens\n",
        "vocab = set(flatten(seq_in))\n",
        "slot_tag = set(flatten(seq_out))\n",
        "intent_tag = set(intent)\n",
        "\n",
        "Code cell <undefined>\n",
        "# %% [code]\n",
        "# adds paddings\n",
        "sin=[] #padded input tokens\n",
        "sout=[] # padded output translated tags\n",
        "sin_test=[] #padded input tokens\n",
        "sout_test=[] # padded output translated tags\n",
        "## adds padding inside input tokens\n",
        "def add_paddings(seq_in,seq_out):\n",
        "    sin=[]\n",
        "    sout=[]\n",
        "    for i in range(len(seq_in)):\n",
        "        temp = seq_in[i]\n",
        "        if len(temp)<LENGTH:\n",
        "            while len(temp)<LENGTH:\n",
        "                temp.append('<PAD>')\n",
        "        else:\n",
        "            temp = temp[:LENGTH]\n",
        "        sin.append(temp)\n",
        "        # add padding inside output tokens\n",
        "        temp = seq_out[i]\n",
        "        if len(temp)<LENGTH:\n",
        "            while len(temp)<LENGTH:\n",
        "                temp.append('<PAD>')\n",
        "        else:\n",
        "            temp = temp[:LENGTH]\n",
        "        sout.append(temp)\n",
        "    return sin,sout\n",
        "sin,sout=add_paddings(seq_in,seq_out)\n",
        "sin_test,sout_test=add_paddings(seq_in_test,seq_out_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "RmWXD3ncNKqv",
        "outputId": "fc78e0a3-694f-4407-c3d6-a326e88a806f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-14-7e41e9ec8e53>, line 54)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-7e41e9ec8e53>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    0KB\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ]
    }
  ]
}